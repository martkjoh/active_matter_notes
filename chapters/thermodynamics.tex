%%%%%%%%%%%%%
% Lecture 4 %
%%%%%%%%%%%%%

In this lecture, we give an overview of the thermodynamic tools that we have at our disposal for the characterization of active matter. 
As mentioned in Lecture 1, active matter defies thermodynamic equilibrium at the local scale. Some of the consequences of this property are: (i) the absence of a minimization principle for the steady-state statistics; (ii) the breaking of time-reversal symmetry of the steady-state dynamics; (iii) the absence of a generic thermodynamic framework. These are all related, as we will demonstrate shortly, via the concept of entropy production, which provides a measure of ``distance'' from equilibrium.


\section{Guessing the arrow of time}

Imagine being given the equation of motion of a particular process, after which a video of a sample realization of said process starts playing. How can you guess whether the video is currently being played in its original form, or whether it has been reversed?

Optimal decision theory, in particular Wald's ratio test \cite{PhysRevLett.115.250602}, tells us that the best time to make a guess between two competing hypotheses (here F=forward movie, B=backward movie) is the first occurrence of the quantity 
%
\begin{equation}\label{eq:Q_def}
    Q = \ln \frac{P(F|O)}{P(B|O)}
\end{equation}
%
reaching either of the pre-defined values $\pm Q^*$ (i.e. it is a first passage problem),
where $P(F,B|O)$ denotes the posterior probability of either F or B being true given an observed realization $O$ of the process. We can equivalently write,
%
\begin{equation}
    P(F|O) = \frac{1}{2} + \frac{\tanh(Q)}{2},\quad P(B|O) = \frac{1}{2} - \frac{\tanh(Q)}{2}~,
\end{equation}
%
whereby $Q^*$ can be translated into a given degree of confidence about our guess. Using Bayes' theorem,
%
\begin{equation}
    P(F|O) = \frac{\mathbb{P}(O|F)P(F)}{\mathbb{P}(O)}
\end{equation}
%
and similarly for $P(B|O)$,
where we introduced the notation $\mathbb{P}$ to highlight the fact that these are ``path probabilities'' associated with a particular trajectory $O = \{o(t)\}_0^\tau$ of duration $\tau$. We set our prior probabilities $P(F) = P(B) = 1/2$ and substitute into \eqref{eq:Q_def} to obtain
%
\begin{equation}\label{eq:Q_def_paths}
    Q[O = \{o(t)\}_0^\tau] = \ln \frac{\mathbb{P}(O|F)}{\mathbb{P}(O|B)}~.
\end{equation}
%
Now, since all possible sample trajectories, whether played backward or not, originate from the original dynamics, we conclude that $\mathbb{P}(O|B) = \mathbb{P}(\hat{\Omega} O|F)$ with $\hat{\Omega}$ the time-reversal operator, i.e. the probability of being shown a particular trajectory O \emph{given that it was time-reversed} is simply the probability of the corresponding time-reversed trajectory $\hat{\Omega}O$ in the forward ensemble. It should be noted that the operator $\hat{\Omega}$ acts differently on different types of observables, depending in particular on their \emph{signature} under time-reversal: even quantities, such as densities and position, are invariant under time-reversal, while odd quantities, such as velocities and magnetic fields, change sign.

The quantity $Q[O]$ appearing in \eqref{eq:Q_def_paths} is a random variable, being a functional of a random path. To determine the mean rate with which confidence about our guess of the arrow of time is built, we average with respect to the ensemble of possible observed trajectories and divide by the trajectory duration
%
\begin{equation}
    \dot{\bar{Q}} \equiv \frac{\bar{Q}}{\tau} = \frac{1}{\tau} \int \mathcal{D}O \ \mathbb{P}(O|F) \ln \frac{\mathbb{P}(O|F)}{\mathbb{P}(O|B)}~.
\end{equation}
%
The structure in the right-hand side can be recognized as the Kullbeck-Leibler divergence \cite{kullback1951information} per unit time of the forward and time-reversed ensembles. This is a standard measure of statistical distinguishibility, vanishing when the two path probability distributions are identical. \\

Let us now compute this quantity for a simple case, specifically one-dimensional Brownian motion in the presence of an external position-dependent force. The governing Langevin equation reads
%
\begin{equation}
    \dot{x}(t) = \mu F(x(t)) + \sqrt{2k_B T \mu} \eta(t)
\end{equation}
%
where $\eta$ is a zero-mean Gaussian white noise of unit covariance, $\langle \eta(t)\eta(t')\rangle = \delta(t-t')$. In discrete time,
%
\begin{equation}
    dx_t = \mu F(x_t) dt + \sqrt{2k_B T \mu dt} \eta_t
\end{equation}
%
with $\eta_t \sim \mathcal{N}(0,1)$ now a set of iid zero-mean, unit variance Gaussian random variables. Thus, the probability of a particular realization of the noise has a simple factorized form,
%
\begin{equation}
    \mathbb{P}[\{\eta_t\}] \propto \prod_{i=0}^{\tau/dt} {\rm exp}\left( - \frac{\eta_i^2}{2} \right) 
    = {\rm exp}\left( - {\sum}_i \frac{\eta_i^2}{2} \right)~.
\end{equation}
%
Given a particular initial condition $x(0)$, any trajectory $x(t \in [0,\tau])$ is uniquely defined by the corresponding noise realisation $\eta(t \in [0,\tau])$. Thus, for an observable $A[x(t)]$ depending on $x(t)$ we can write expectations as
%
\begin{equation}
    \langle A \rangle = \int \mathcal{D}\eta \ \mathbb{P}[\eta] A[x[\eta]] = \int \mathcal{D}x \ \underbrace{\mathbb{J}[x] \tilde{\mathbb{P}}[x]}_{\mathbb{P}[x]} A[x]
\end{equation}
%
where we have performed a change of variable by including the relevant Jacobian $\mathbb{J}[x] \equiv \mathcal{D}\eta/\mathcal{D}x$. Whether the latter is a trivial quantity or not, depends on the implicit convention about the interpretation of the relevant stochastic integrals (Ito vs Stratonovich, or generalizations thereof \cite{tauber2014critical}). This discussion falls beyond the scope of this course so we sweep this difficulty under the carpet and simply take for granted that $\mathbb{J}[x] = \mathbb{J}[\hat{\Omega}x]$ is invariant under time-reversal and that the Stratonovich mid-point convention can be assumed when looking at products of random variables (the only discretization that allows for straightforward use of the standard chair rule of calculus). With all these caveats out of the way, we may write
%
\begin{equation}
    \mathbb{P}[x|F] \propto {\rm exp}\left( - \frac{1}{2} \sum_i \frac{(dx_t - \mu F(x_t)dt)^2}{2k_B T \mu dt} \right) \propto {\rm exp}\left( - \frac{1}{4k_B T \mu} \int dt\  [\dot{x}(t) - \mu F(x(t))]^2 \right)
\end{equation}
%
having taken the continuum limit $dt \to 0$. Recalling that positions and velocities are even and odd under time reversal, respectively, we then have
%
\begin{align}
    \mathbb{P}(x|B) \propto {\rm exp}\left( - \frac{1}{4k_B T \mu} \int dt\  [-\dot{x}(t) - \mu F(x(t))]^2 \right)
\end{align}
%
whence
%
\begin{equation}\label{eq:q_vs_eqr}
    \dot{\bar{Q}} = \frac{\langle \dot{x}(t) F(x(t))\rangle}{k_B T}~. 
\end{equation}
%
Note how the numerator in the right-hand side of this expression is a product of the particle velocity times the force applied to it, and can thus be interpreted as the stochastic work done per unit time on the particle by the external force \cite{sekimoto1998langevin}. At steady-state, due to the conservation of energy, that same power needs to be dissipated as heat into the bath providing the thermal fluctuations. This quantity is thus nothing but the rate of entropy generation in the heat reservoir, $ \dot{\bar{Q}} = \dot{\sigma}$. This is a sign of the profound connection between entropy production as an informatic measure of time-reversal symmetry breaking, and its more traditional thermodynamic interpretation \cite{gaspard2004time}. In the following sections, we will follow a more traditional, i.e.\ thermodynamic, path for the derivation of this quantity.

Before moving on, let us note one important property of \eqref{eq:q_vs_eqr}. For conservative forces originating from an external potential that is bounded below and constant in time, $F(x) = -\partial_x U(x)$, we have by the chain rule that $\langle \dot{x}(t) F(x(t))\rangle = -\langle \dot{U} \rangle = 0$. In other words, the steady state of Brownian dynamics in a stable potential is equilibrium/time-reversal symmetric. 



% Handwritten notes section (2)

\section{Gibbs-Shannon entropy (axiomatically)}

We briefly motivate the form of the Gibbs-Shannon entropy, which we will use in the following section. This can be derived ``axiomatically'' by imposing the following requirements on the thermodynamic entropy $S(\{p_i\}_{i=1,...,M})$ of a statistical ensemble, assuming for simplicity a discrete state space:

\begin{enumerate}
    \item For separate systems A and B treated as a single system, $S(A \cup B) = S(A) + S(B)$. Statistically speaking, the systems being ``separate'' or ``non-interacting'' means that the joint probability $p(a \in A, b \in B) = p(a)p(b)$ factorises ;
    \item Continuity/smoothness with $p_i$;
    \item $S(\{p_i\})$ should have a minimum $S=0$ when $p_i = 1$, $p_{j\neq i} = 0$ for some $i$;
    \item $S(\{p_i\})$ should have a positive maximum when $p_i = 1/M$ for all $i$.
\end{enumerate}
The Gibbs-Shannon entropy satisfies all these constraints,
%
\begin{equation}
    S_{GS} = -k_B \sum_i p_i \ln p_i~.
\end{equation}
%
The ``modern'' view of thermodynamics ({\`a} la Callen) takes the entropy as the fundamental quantity. For example, the ideal gas equations of state can be derived from the Sackur-Tetrode entropy
%
\begin{equation}
    S = \frac{3}{2}N k_B \ln \epsilon + N k_B \ln V + N k_B \left[ \ln\left( N^{-1} \left( \frac{4\pi m}{2Nh^2}\right)^{\frac{3}{2}} + \frac{5}{2} \right) \right]~,
\end{equation}
%
with intensive quantities following from suitable differentiation, e.g.
%
\begin{equation}
    P \equiv T \frac{\partial S}{\partial V} = \frac{Nk_B T}{V}~.
\end{equation}
%
% Handwritten notes section (2)
Similarly, the Boltzmann distribution of equilibrium thermodynamics, which applies to open systems coupled to a heat reservoir, can be obtained by maximizing the Gibbs-Shannon entropy while keeping the mean energy fixed (max-ent principle). In particular, one can check that $p_i \propto e^{-\beta E_i}$ with $\beta^{-1} = k_B T$ maximises the functional
%
\begin{equation}
    \mathcal{L}[\{p_i\}] = -k_B \sum_{i} p_i \ln p_i + \lambda_1 \left(\sum_i E_i p_i - \epsilon \right) + \lambda_2 \left(\sum_i p_i - 1 \right) 
\end{equation}
%
where $\epsilon = \langle E_i \rangle$ is the mean energy, while $\lambda_1$ and $\lambda_2$ are Lagrange multipliers enforcing the constraint on the mean energy and normalization, respectively.



\section{Entropy production rate from Gibbs-Boltzmann entropy}

% Handwritten notes section (4)

We now demonstrate how a formula analogous to \eqref{eq:q_vs_eqr} can be derived from thermodynamic, rather than informatic, considerations, taking the Gibbs-Boltzmann entropy as a starting point. 
%The entropy production rate (EPR) is exactly what it sounds like, the amount of entropy produced per unit of time.
Given a system that evolves stochastically with time, which we assume to be discrete for simplicity, we can write the Markov master equation
%
\begin{align}
    \odv{  }{ t } P_i(t) = \sum_j K_{ij} P_j(t),
\end{align}
%
where $K_{ij}$ denotes the (Poisson) rate of transitioning from state $j$ to state $i$. The transition rates must obey $\sum_i K_{ij} = 0$ to conserve probability.
The corresponding Gibbs-Shannon entropy is
%
\begin{align}
    S(t) = - \sum_i P_i(t) \ln P_i(t),
\end{align}
%
which allows us to directly compute the rate of change of the entropy
%
\begin{align}
    \odv{  }{ t } S(t)
    \equiv \dot S(t)
    & = - \underbrace{{\sum}_i \dot P_i(t)}_{= 0}
    - \sum_i \dot P_i(t) \ln P_i(t)\\
    & = 
    -\frac{1}{2}\sum_{ij}
    \left(
        K_{ij}P_j \ln P_i
        + K_{ji} P_i \ln P_j
    \right) 
\end{align}
%
where we have inserted the master equation, and rewritten the sum as two copies where the dummy indices are renamed. Assuming that a statistical steady-state exists, we have that $\lim_{t \to \infty} \dot{S}(t)=0$ and in this limit $P_i$ converges to the eigenvector of $K$ with eigenvalue zero.
With some more massaging, we can write this as
%
\begin{align}
    \dot S(t) &=
    -\frac{1}{2}\sum_{ij}
    \left(
        K_{ij}P_j \ln P_i
        + K_{ji} P_i \ln P_j
    \right) \\
    & =
    -\frac{1}{2}\sum_{ij}
    \left(
        K_{ij}P_j \ln P_i
        - K_{ij} P_{j} \ln P_j
        + K_{ji} P_{i} \ln P_i
        + K_{ji} P_i \ln P_j
    \right) \\
    & =
    -\frac{1}{2}\sum_{ij}
    \left(
        K_{ij}P_j \ln \frac{P_i}{P_j}
        - K_{ji} P_i \ln \frac{P_i}{P_j}
    \right) 
    %\\
    %& 
    -\frac{1}{2}\sum_{ij}
    \left(
        K_{ij}P_j 
        - K_{ji} P_i 
    \right) \ln \frac{P_i}{P_j}\\
    & =
    -\frac{1}{2}\sum_{ij}
    \underbrace{
        ( K_{ij}P_j - K_{ji} P_i) 
        }_{{{\mathcal J}_{ij}}}
    \ln
    \left(
        \frac{K_{ji }P_i}{K_{ij}  P_j}
        \frac{K_{ij}}{K_{ji}}
    \right)
    \equiv \dot S_e + \dot \sigma~, \label{eq:epr_decomp}
\end{align}
%
where $\mathcal J_{ij}$ is the net probability current from state $j$ to state $i$.
In the last step, we have defined the external entropy production rate or entropy flow,
%
\begin{align}
    \dot S_e = - \frac{1}{2}\sum_{ij}
        ( K_{ij}P_j - K_{ji} P_i) 
    \ln \left( \frac{K_{ij}}{K_{ji}}\right) = - \sum_{i<j} \frac{\mathcal J_{ij} \Delta Q_{ij}}{k_b T}
\end{align}
%
which quantifies the rate of increase in total entropy due to heat dissipation from the system to the isothermal environment. To see this, we have invoked an important physical principle known as \emph{local detailed balance}, which formally amounts to demanding 
\begin{align}
    \frac{K_{ij}}{K_{ji}} = e^{\Delta Q_{ij} / k_b T}~,
\end{align}
i.e.\ that the ratio of forward and backward rates associated with a microscopically reversible transition between two states is equal to the exponential of the heat release in the transition, $\Delta Q_{ij}$, in units of the thermal energy scale. It should be noted that this relation is introduced on physical grounds and might not apply in all cases. In cases where it does apply, it can often be justified using Kramer's reaction rate theory.

Eq.~\eqref{eq:epr_decomp} additionally defines the total entropy production rate
%
\begin{align}
    \dot \sigma = 
    \frac{1}{2}\sum_{ij}
    \left(K_{ij}P_j - K_{ji} P_i\right) 
    \ln \left( \frac{K_{ij}P_j}{K_{ji} P_i}\right), \label{eq:epr_int_discr}
\end{align}
%
which obeys $\dot \sigma \geq 0$. To see that $\dot \sigma$ is non-negative, consider that $(a-b)\ln(a/b) > 0$ for all $a,b>0$.
Thus the total entropy production rate can be written as 
%
\begin{align}
    \dot \sigma = \dot S + \frac{\dot Q}{k_b T} \geq 0,
\end{align}
%
which is the second law of thermodynamics!
At a steady state, the probability distribution $P$ is independent of time, so $\dot S = 0$, which gives
%
\begin{align}
    \dot \sigma = \frac{\dot Q}{k_b T}~.
\end{align}
Thus, finite entropy production in a steady state (a signature of activity) must be accompanied by a finite rate of heat dissipation into the surrounding environment.
%
Indeed, it is also possible to show that \eqref{eq:epr_int_discr} corresponds to the Kullbeck-Leibler divergence per unit time of the ensemble of forwards vs backward paths on the discrete state space \cite{gaspard2004time}, completing the parallel with the calculation presented in the first part of this lecture. 




\section{(Non)conserved active field theories: fluctuation-dissipation}

% Handwritten notes section (5, 5b)


We now consider the thermodynamics of systems described at a more coarse grain level, using \emph{hydrodynamic theory}. 
In this case the relevant degrees of freedom are fields, which follow Langevin-field equations.
These are to Langevin equations as PDEs are to ODEs.
If we assume the density $\psi(\bm x)$ is not conserved, as is the case if we consider magnetization, driven quantum systems such as polariton Bose-Einstein condensates, or a density of cells that are born and die, we may generically write the equation of motion as
%
\begin{align}
    \partial_t \psi(\bm x, t) 
    = M[\psi(\bm x, t)] G_\psi[\psi(\bm x, t), \bm \nabla \psi(\bm x, t)] 
    + \sqrt{ 2 k_B T \tilde M[\psi(\bm x, t)] } \eta(\bm x, t).
\end{align}
%
In the simplest case, the mobilities $M$ and $\tilde{M}$ are constant, but in principle, they can have a more complicated dependence on the field.
For model A in the Halperin-Hohenberg (HH) classification~\cite{HohenbergRMP}, the potential takes the form $G = -(a \psi + b \psi^3 + \kappa \nabla^2 \psi)$ with $M=\tilde{M}=\gamma^{-1}$. 
%

In the case of, for example, a non-degrading chemical density, the order parameter $\rho$ is conserved, and its equation of motion is the conservation law (aka continuity equation)
%
\begin{align}
    \partial_t \rho(\bm x, t)
    = 
    \bm \nabla\cdot
    \left[
        M[\rho(\bm x, t)]
        \bm \nabla G_\rho[\rho(\bm x, t), \bm \nabla\rho(\bm x, t)]
        + \sqrt{ 2 k_B T \tilde M[\rho(\bm x, t)] }
        \bm \eta(\bm x, t)
    \right]~.
\end{align}
%
Here again, the mobilities are constant in the simplest case.
For model B in the HH classification, the forces are given by $\bm \nabla G_\rho = \bm \nabla (a \rho + b \rho^3 - \kappa \nabla^2 \rho)$ with $M = \tilde{M} = \gamma^{-1}$.

Model A is the canonical stochastic field theory for describing the spontaneous symmetry-breaking of the Ising model, while model B plays a similar role for the diffusive phase separation of a conserved scalar.
We capture both models at once by writing
%
\begin{align}
    \partial_t \phi(\bm x, t)
    = 
    \bm \nabla^{(k)}
    \left[
        M[\rho(\bm x, t)]
        \bm \nabla^{(k)} G_\rho[\rho(\bm x, t), \bm \nabla\rho(\bm x, t)]
        + \sqrt{ 2 k_B T  Q[\rho(\bm x, t)] }
        \bm \eta(\bm x, t)
    \right]
\end{align}
%
Here, $k = 0$ in the case of model A, and $k = 1$ in the case of model B.
Solving for the noise, we get
%
\begin{align}
    \eta
    = 
    \frac{[\nabla^{(k)}]^{-1} \partial_t \phi + M[\phi] \nabla^{(k)} G}{\sqrt{ 2 k_B T Q(\phi) }}.
\end{align}
%
We now draw on the Onsager-Machlup function for the path probabilities, which was introduced in the first part of the lecture, to calculate the average rate of entropy production associated with the field dynamics. Once again, the idea is to relate the probability of a certain history of the field to the probability of the corresponding noise realisation, keeping in mind that an additional integral over space needs to be introduced to account for the spatially-extended nature of the fluctuations,
%
\begin{align}
    \mathbb{P}_F[\phi] \propto
    \exp 
    \left\{ 
        - \frac{1}{4 k_B T}
        \int_0^\tau \dd t \int \dd^d r \, \frac{[(\nabla^{(k)})^{-1} \partial_t \phi - M(\phi) \nabla^{(k)}G]^2}{Q[\phi]}
     \right\}.
\end{align}
%
The probability for the reverse path is $\mathbb{P}_R[\phi, \dot \phi] = \mathbb{P}_F[\phi, -\dot \phi]$,  so the log ratio of the path probabilities becomes
%
\begin{align}
    \ln \frac{\mathbb P_F}{\mathbb P_R}
    = 
    \frac{1}{k_B T}
    \int_0^\tau \dd t\ \int \dd^d r \, \partial_t \phi [\nabla^{(k)}]^{-1}
    \left[
        \frac{M[\phi]}{Q[\phi]}
        \nabla^{(k)}G(\phi)
    \right].
\end{align}
%
In the case of equilibrium, the fluctuation-dissipation theorem (FDT) means that $M = Q$, and the forces are given by minimizing free energy, $G =\fdv{F}{\phi}$.
The integral may thus be easily solved,
%
\begin{align}
    \int_0^\tau \dd t\ \int \dd^d r \, \partial_t \phi [\nabla^{k}]^{-1}
    \left[
        \nabla^{(k)}\fdv{F}{\phi}
    \right]
    = 
    \int_0^\tau \dd t\, \odv{}{t} F(t)
    = 
    F(\tau) - F(0),
\end{align}
%
which means the path probabilities follow detail balance
%
\begin{align}
    \frac{\mathbb P_F}{\mathbb P_R} = e^{\Delta F / k_B T}.
\end{align}
%
Furthermore, as long as $F$ is bounded from below, the Kullbeck-Leibler divergence per unit time, $\langle F(\tau)-F(0)\rangle/\tau$, will vanish at steady state as $\tau \to \infty$ and necessarily so will the total entropy production $\dot\sigma$.
When either the FDT is not satisfied by our (a priori generic) choice of $M$ and $Q$, or the generalized force $G$ cannot be expressed as the functional derivative of a free-energy-like functional, all the above simplifications fail to apply and we should expect a non-vanishing value of $\dot\sigma$.

As an example of how this undestanding can help us build models of active matter, take a ``dry'' active field theory for a conserved density.
This can typically be written as a conservation law,
%
\begin{align}
    \partial_t \rho = - \bm \nabla \cdot \bm J,
\end{align}
%
where the current can be split into an active and a passive term, $\bm J = \bm J^a + \bm J^p$.
The passive terms alone are equilibrium effects and therefore have the form
%
\begin{align}
    \bm J^p = - M \bm \nabla \fdv{F}{\rho} + \sqrt{2 k_B T M} \bm \eta
\end{align}
%
satisfying both FDT and the derivative structure of the force.
Note that this might still be an ``effective'' passive term, i.e. the dynamics could still originate from activity at the microscopic level, but such activity might lead to effective equilibrium dynamics of the slow modes on a coarse-grained level.
The active current, on the other hand, can generically be written as
%
\begin{align}
    \bm J^a = \sum_i \lambda_i \times (\text{active terms}).
\end{align}
%
Here, $\lambda_i$ are sometimes referred to as activity parameters \cite{cates2022active}.

\subsubsection{Example: dry polar active matter}

For the case of dry polar active matter, we may write $\bm J^{a} = \lambda_1 \rho \bm p$ with $\bm p$ the local polar order parameter to indicate, e.g., that particles like to self-propel in the direction of their polarity, leading to additional currents in regions where particles are oriented in a similar direction. To close our system of equations, we then need to include a second Langevin-field equation
%
\begin{align}
    \partial_t \bm p + \lambda_2 \bm p \cdot \bm \nabla \bm p
    = - \Gamma \fdv{F}{\bm p} + \sqrt{ 2 k_B T\Gamma } \bm \eta.
\end{align}
%
This reduces to the ``Toner-Tu model'' of dry flocking, if we set $M\rightarrow 0$, with a particular choice of free energy
%
\begin{align}
    F = \int \dd x \, 
    \left(
        \frac{1}{2}a p^2 + \frac{1}{4}b p^4 + \frac{1}{2} \bm \nabla \bm p : \bm \nabla \bm p
        - \bar \omega \bm \nabla \cdot \bm p \rho + \frac{\lambda}{2 \Gamma} p^2 \bm \nabla \cdot \bm p
    \right)
\end{align}
%
``Wet'' active matter is more complicated, as we need to include the Navier-Stokes (NS) equation for the surrounding fluid.
We will say a bit about this later.

What we have done until now is a \emph{top-down approach}, where we add minimal active terms based on physical intuition and the symmetries of the microscopic description.
A \emph{bottom-up approach} typically starts with a description of the microscopic dynamics and proceeds via a formal coarse-graining procedure.
This is typically much harder, and you often end up with the same macroscopic theories, but with the additional advantage of having a microscopic interpretation of the terms in the hydrodynamic equations. In particular, it might be possible to establish a clear relationship between the effective parameters of the coarse-grained theory and those of the microscopic dynamics, essential for connection with experiments.

For dynamics near equilibrium, linear irreversible thermodynamics gives us a more systematic (although still top-down) recipe to construct hydrodynamic theories. We briefly review this approach in the following.


\section{A primer on linear irreversible thermodynamics}

The following is based on the more extended discussions in \cite{pottier2009nonequilibrium} and \cite{de2013non}. Consider the dynamics of a set of $N+M$ interacting fields $\{\phi_i\}_{i=1}^N\cup \{\rho_j\}_{j=1}^M$, where $\phi$ and $\rho$ denote non-conserved and conserved densities, respectively.
The rate of change of the energy $\mathcal{F} = U - TS$ under isothermal conditions is
%
\begin{align}
    \dot{\mathcal{F}} = \dot U - T \dot S
    = 
    -\int \dd r \, 
    \left[
        \sum_{i} \dot \phi_i \left(-\fdv{\mathcal{F}}{\phi_i}\right)
        + \sum_{j} \dot \rho_j \left(- \fdv{\mathcal{F}}{\rho_j}\right)
    \right].
\end{align}
%
Again, we assume that $\rho_j$ follows the conservation law
%
\begin{align}
    \partial_t \rho_j = \bm \nabla \cdot \bm J^{(c)}_j,
\end{align}
%
while the current of $\phi$, $\dot \phi_i = J^{(nc)}_i$, is non-conserved.
We define the effective/thermodynamic forces as
%
\begin{align}
    F_i^{(nc)} &= - \fdv{\mathcal{F}}{\phi_i} &
    \bm F_j^{(c)} &= - \bm \nabla \fdv{\mathcal{F}}{\rho_j}.
\end{align}
%
With this, and after integration by parts, the change in free energy takes the form of fluxes times force,
%
\begin{align}
    \dot{\mathcal{F}} = 
    - \int \dd r \,
    \left(
        \sum_i J_i^{(nc)} F_i^{(nc)} 
        + \sum_j \bm J_j^{(c)} \cdot \bm F_j^{(nc)}
    \right).
\end{align}
%
Given that the free energy $\mathcal{F}$ is invariant under time reversal and assuming well-defined parity under time reversal of the fields $\phi$ and $\rho$, it follows
that the effective forces also have well-defined parity under time reversal. 
On the other hand, the fluxes $J^{(nc)}$ and $J^{(c)}$ are as of yet unconstrained and can in general have both contributions
%
\begin{align}
    J_i^{(nc)} &=  J_{R,i}^{(nc)} + J_{D,i}^{(nc)},  &
    \bm J_j^{(c)} &=  \bm J_{R,j}^{(c)} + \bm J_{D,j}^{(c)}.
\end{align}
%
Here we have split the currents into ``reactive'' fluxes, which have the opposite time-reversal signature as the associated force, thus contributing to $\dot U$, and ``dissipative'' fluxes, which have the same time-reversal signature of the associated force and contribute to $T \dot S$.


At equilibrium, all forces and fluxes vanish.
In a ``small neighborhood'' of the equilibrium state, we will assume the existence of linear phenomenological laws.
These take the form
%
\begin{align}
    J_{\bullet,i}
    = L_{ij}(\{\phi_i\}, \{\rho_j\}) F_j, 
\end{align}
%
with $\bullet \in \{R,D\}$ and are called \emph{constitutive equations}. Note that we have dropped the superscript distinguishing currents of (non)conserved fields for the sake of readability.
Here $F_j$ enumerates generalized forces acting on both conserved and non-conserved fields: it is \emph{not} the case that currents of conserved fields can only depend on effective forces acting on conserved fields, and similarly for non-conserved fields. However, it \emph{is} the case that current contributions with a given signature under time reversal can only depend on generalized forces with the same signature. 

The matrix $L_{ij}$ is made up of \emph{transport coefficients}, which can in general be functions of the fields themselves.
Again, in these laws, all couplings with equal time-reversal signatures are allowed.
The fact that $\mathcal{F}$ is minimized at equilibrium implies that $L$ should be positive definite, since we can write
\begin{equation}
    \dot{\mathcal{F}} = - F_i L_{ij} F_j \leq 0~.
\end{equation}
The possible values of the transport coefficients $L_{ij}$ can be further constrained based on the following physical principles:
\begin{itemize}
    \item {\bf Curie's principle} states that the tensorial structure of currents and forces must be matched in the constitutive equation, e.g. vector currents need to be a sum of vector-like objects that transform in the same way under rotation, etc.
    \item Furthermore, the {\bf  Onsager-Casimir relations}, rooted in the microscopic reversibility of Hamiltonian dynamics, state that dissipative fluxes must have symmetric (under transposition) couplings, while reactive fluxes must have antisymmetric couplings.
    In other words,
    %
    \begin{equation}
        L_{ij}  = \epsilon_i \epsilon_j L_{ji},
    \end{equation}
    %
    where $\epsilon_i = \pm 1$ are the parity of the associated force.
\end{itemize}

\subsubsection{Example: active gel theory}

As an example, take the case of a ``wet'' system consisting of a fluid (with velocity $v$) coupled to a non-conserved polar field (q) and to the non-conserved scalar density of chemical species, e.g. ATP (r). This is sometimes referred to as an active gel theory \cite{kruse2005generic}.
For the purpose of this example, let us just assume that the time derivative of the free energy can be written as 
%
\begin{align}
    \dot{\mathcal{F}} = - \int \dd r 
    \left(\sigma_{\alpha \beta} u_{\alpha \beta} + h_\alpha D_t q_\alpha + \Delta_\mu \dot r\right)
\end{align}
%
where $\sigma$ is the stress tensor, $u$ is the symmetrized strain rate tensor, $h$ is the crystal field, $D_t q$ is the comoving \& corotational time derivative of the local polarity, $\Delta\mu$ is the chemical free energy associated with the removal of a particle of chemical from the system and $\dot{r}$ is the instantaneous rate of particle removal.
Categorizing this as above, we have

\begin{table}[h]
\centering
\begin{tabular}{c|c|c}
    Fluxes & Forces & Parity of Force \\
    \hline
    $\sigma_{\alpha \beta}$ 
    & $u_{\alpha \beta} = \frac{1}{2}(\partial_\alpha v_\beta + \partial_\beta v_\alpha)$ 
    & $\epsilon = -1$\\
    $D_t q_\alpha$ &
    $\fdv{F}{q_\alpha} = h_\alpha$ & $\epsilon = +1$ \\
    $\dot r$ & 
    $\fdv{F}{r} = \Delta_\mu$ & 
    $\epsilon = +1$ \\
\end{tabular}
\end{table}

We split the fluxes into the reactive and diffusive parts, according to the parity under time-reversal of the corresponding force
%
\begin{align}
    \sigma_{\alpha \beta} 
    & = \underbrace{\sigma_{\alpha \beta}^{(R)}}_{\epsilon=+1}
    + \underbrace{\sigma_{\alpha \beta}^{(D)}}_{\epsilon=-1}\\
    D_t q_\alpha
    & = \underbrace{D_t p_\alpha^{(R)}}_{\epsilon=-1}
    + \underbrace{D_t p_\alpha^{(D)}}_{\epsilon=+1}\\
    \dot r
    & = \underbrace{\dot r^{(R)}}_{\epsilon=-1}
    + \underbrace{\dot r^{(D)}}_{\epsilon=+1}.
\end{align}
%
We now proceed to introduce linear phenomenological relations by writing fluxes as linear superpositions of forces with suitable time-reversal signatures. We see immediately that, for example, $\sigma^{(D)} \propto u$, since this is the only force that is odd under time reversal, as required.
Following similar arguments, we must have
%
\begin{align}
    D_t q_\alpha^{(D)} &= \lambda_{qq} h_\alpha + \lambda_{qr} \Delta_\mu \\
    \dot r^{(D)} &= \lambda_{rr} \Delta_\mu + \lambda_{rq} h_\alpha.
\end{align}
%
By Onsager reciprocity, we further need to impose $\lambda_{pr}(r, q) = \lambda_{rp}(r, q)$, and by Curie's principle, we also demand that $\lambda_{q r} \propto q$, as each term in the right-hand side of the first (second) equation needs to be a vector (scalar).
On the other hand, $D_t q_\alpha^{(R)}$ and $\dot r^{(R)}$ cannot depend on $h$ and $\Delta_\mu$ due to time-parity mismatch. They will thus only depend on $u$ via coefficients involving the polarity as required to combine with $u$ into a vector and a scalar respectively.
Using the Onsager relations, we get, for the terms coupling fluid velocity and chemical reaction rate
%
\begin{align}
    \sigma_{\alpha \beta}^{(R)} 
    &= \dots
    \left(- \xi p_\alpha p_\beta - \bar \xi \delta_{\alpha \beta} - \xi' p_\gamma qp_\gamma \delta_{\alpha \beta}\right)
    \Delta_\mu, \\
    \dot r^{(R)} 
    &= -
    \left(- \xi p_\alpha p_\beta - \bar \xi \delta_{\alpha \beta} - \xi' p_\gamma p_\gamma \delta_{\alpha \beta}\right)
    u_{\alpha \beta}~.
\end{align}
As one might suspect, this approach to constructing a field theory typically leads to models that are somewhat too generic to be amenable to analytical treatment. Approaches based on linear irreversible thermodynamics often proceed by reducing the number of parameters by physically arguing for the irrelevance of some of the ``off-diagonal'' couplings introduced along the way. 
